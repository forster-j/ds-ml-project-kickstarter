{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kickstarter Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of relevant columns\n",
    "\n",
    "* backers_count: amount of people pledging money to the project                                     \n",
    "* category -> 'slug': name of the projects' specific parent- & sub-category (part of json string)\n",
    "* country: country of the projects creator \n",
    "* creator -> 'id': id of the creator -> to be used as categorical variable (part of json string)\n",
    "* goal: information on the amount of money needed to succeed in the local currency of the project\n",
    "* launched_at: start date? of the project ()\n",
    "* deadline: end date of the project ()\n",
    "* spotlight: project highlighted on the website\n",
    "* staff_pick: marked by a staff member of kickstarter (more attention drawn towards project)\n",
    "* state: (successful/failed/canceled/live/suspended) -> exclude 'live' and combine 'canceled', 'suspended' with 'failed'\n",
    "* static_usd_rate: exchange rate to transform goal in every column from current currency to USD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stakeholder: Project creator \n",
    "### Question: Is it useful to put much effort into launching a campaign on kickstarter? \n",
    "### Measure: Is the campaign likely to succeed or fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "df = pd.read_csv('data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'] = df['state'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('state', axis=1)\n",
    "y=df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print accuracy score \n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred).round(2))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred).round(2))\n",
    "print(\"-----\" * 10)\n",
    "\n",
    "# Print confusion matrix with values\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGn', cbar=False, annot_kws={\"size\": 16})\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Standardization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we have a look at the different methods, \n",
    "# we have to define which columns we want to scale.\n",
    "col_scale = ['slug', 'launched_at_weekday', 'launched_at_month',\n",
    "       'duration_days', 'goal_in_usd' , 'north_america']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling with standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[col_scale])\n",
    "X_test_scaled = scaler.transform(X_test[col_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating scaled and dummy columns \n",
    "X_train_preprocessed = np.concatenate([X_train_scaled, X_train.drop(col_scale, axis=1)], axis=1)\n",
    "X_test_preprocessed = np.concatenate([X_test_scaled, X_test.drop(col_scale, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_scale1 = ['slug', 'launched_at_weekday', 'launched_at_month',\n",
    "       'duration_days', 'goal_in_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling with MinMaxScaler\n",
    "# Try to scale you data with the MinMaxScaler() from sklearn. \n",
    "# It follows the same syntax as the StandardScaler.\n",
    "# Don't forget: you have to import the scaler at the top of your notebook. \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[col_scale1])\n",
    "X_test_scaled = scaler.transform(X_test[col_scale1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating scaled and dummy columns \n",
    "X_train_preprocessed1 = np.concatenate([X_train_scaled, X_train.drop(col_scale1, axis=1)], axis=1)\n",
    "X_test_preprocessed1 = np.concatenate([X_test_scaled, X_test.drop(col_scale1, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what parameters does KNN have?\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameter grid (as dictionary)\n",
    "param_grid = {\"n_neighbors\" : [3,5,7], #this actually defines the model you use\n",
    "              \"weights\" : [\"uniform\", \"distance\"],\n",
    "              \"p\" : [1, 2, 3],\n",
    "              \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "             }\n",
    "\n",
    "# Instantiate gridsearch and define the metric to optimize \n",
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid, scoring='precision',\n",
    "                  cv=5, verbose=3, n_jobs=-1)\n",
    "\n",
    "# Fit gridsearch object to data.. also lets see how long it takes\n",
    "start = timer()\n",
    "gs.fit(X_train_preprocessed1, y_train)\n",
    "end = timer()\n",
    "gs_time = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best score\n",
    "print('Best score:', round(gs.best_score_, 3))\n",
    "# Best parameters\n",
    "print('Best parameters:', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will do this at least twice.. according to DRY we should write a function\n",
    "def print_pretty_summary(name, model, y_test, y_pred_test):\n",
    "    print(name)\n",
    "    print('=======================')\n",
    "    print('n_neighbors: {}'.format(model.n_neighbors))\n",
    "    print('weights: {}'.format(model.weights))\n",
    "    print('p: {}'.format(model.p))\n",
    "    print('algorithm: {}'.format(model.algorithm))\n",
    "\n",
    "    precision = precision_score(y_test, y_pred_test)\n",
    "    print('Test precision: {:2f}'.format(precision))\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the fitted KNNClassifier model with best parameter combination to a new variable knn_best\n",
    "knn_best = gs.best_estimator_\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_test = knn_best.predict(X_test_preprocessed1)\n",
    "# Let us print out the performance of our model on the test set.\n",
    "knn_precision = print_pretty_summary('KNNClassifier model', knn_best, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy score \n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test).round(2))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test).round(2))\n",
    "print(\"-----\" * 10)\n",
    "\n",
    "# Print confusion matrix with values\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGn', cbar=False, annot_kws={\"size\": 16})\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
