{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import os, json, re\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "######### functions for pre-processing ####################################################################\n",
    "\n",
    "def extract_year_date_month(df, column):\n",
    "    '''Takes a column, converts it to datetime, and creates new columns with day, month and year\n",
    "    The new columns are named:\n",
    "        - column_weekday\n",
    "        - column_month\n",
    "        - column_year\n",
    "    '''\n",
    "    \n",
    "    # Convert column in df to datetime\n",
    "    df[column] = pd.to_datetime(df[column], unit='s')\n",
    "\n",
    "    # extract the day, month, and year components\n",
    "    df[column + '_' + 'weekday'] = df[column].dt.weekday\n",
    "    df[column + '_' + 'month'] = df[column].dt.month\n",
    "    #df[column + '_' + 'year'] = df[column].dt.year\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def duration(df, column1, column2):\n",
    "    '''Returns the duration in days between 2 columns with datetime and puts it into a new colum\n",
    "        - column1: start date\n",
    "        - column2: end date\n",
    "    '''\n",
    "    df['duration_days'] = (df[column2] - df[column1]).dt.days\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_to_usd(df):\n",
    "    return round(df['goal'] * df['static_usd_rate'],2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### Load the data ########################################################## \n",
    "\n",
    "directory = 'Kickstarter_data/'\n",
    "data = pd.DataFrame()\n",
    "relevant_columns = ['category', 'country', 'state', 'static_usd_rate', 'goal', 'launched_at', 'deadline', 'creator']\n",
    "\n",
    "for file in sorted(os.listdir(directory)):\n",
    "    df_temp = pd.read_csv(directory+file)\n",
    "    data = pd.concat([data, df_temp[relevant_columns]], ignore_index=True)\n",
    "\n",
    "\n",
    "##### Cleaning ########################################\n",
    "\n",
    "## drop duplicates\n",
    "    \n",
    "data = data.drop_duplicates(ignore_index =True)   \n",
    "data = data.drop('creator', axis=1)    \n",
    "\n",
    "\n",
    "## Get the categories from the 'category\n",
    "\n",
    "cat_data = data[\"category\"].apply(json.loads)\n",
    "cat_data = pd.DataFrame(cat_data.tolist())\n",
    "data['slug'] = cat_data['slug']\n",
    "data = data.drop(\"category\", axis=1)\n",
    "data[\"slug\"] = data[\"slug\"].apply(lambda x: re.split(r'/', x)[0])\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['slug'] = le.fit_transform(data['slug'])\n",
    "\n",
    "## Work on the 'state' column\n",
    "\n",
    "data = data[data['state'] != 'live'].reset_index(drop=True)\n",
    "data['state'] = data['state'].apply(lambda x: 1 if x == 'successful' else 0)\n",
    "\n",
    "\n",
    "## Work on the time-related columns 'launched_at' and 'deadline'\n",
    "\n",
    "data['launched_at'] = pd.to_datetime(data['launched_at'], unit='s')\n",
    "data['deadline'] = pd.to_datetime(data['deadline'], unit='s')\n",
    "\n",
    "data = extract_year_date_month(data, 'launched_at')\n",
    "data = duration(data, 'launched_at', 'deadline')\n",
    "\n",
    "data = data.drop(['launched_at', 'deadline'], axis=1)\n",
    "\n",
    "## Work on 'goal' column \n",
    "\n",
    "data['goal_in_usd'] = data.apply(convert_to_usd, axis=1)\n",
    "data = data.drop(['static_usd_rate', 'goal'], axis=1)\n",
    "data = data[data['goal_in_usd'] < 1000000]\n",
    "\n",
    "## Work on 'country' column\n",
    "\n",
    "data[\"north_america\"] = data[\"country\"].apply(lambda x: 1 if x in ['US', 'CA'] else 0)\n",
    "data = data.drop('country', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#save Dataframe in csv_file\n",
    "#data.to_csv('data/cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTICS REGRESSION\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "#X = data.drop('state',axis=1)\n",
    "X = data.drop(\"state\", axis =1)\n",
    "y = data[\"state\"]\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# Train-test-split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Modelling\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train_scaled, y_train)\n",
    "y_pred = logistic_regression.predict(X_test_scaled)\n",
    "\n",
    "# Confusion matrix using pandas crosstab\n",
    "conf_matrix= confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True);\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = pd.read_csv('data/cleaned_data.csv')\n",
    "loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
