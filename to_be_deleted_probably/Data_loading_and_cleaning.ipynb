{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer: This notebook contains functions to load the data from the individual csv tables and further perform data cleaning. It is ment to be executed once. The final dataframe is saved as a .csv file, which can then be worked on with regard to machine learning-based classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kickstarter Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of relevant columns\n",
    "\n",
    "* backers_count: amount of people pledging money to the project                                     \n",
    "* category -> 'slug': name of the projects' specific parent- & sub-category (part of json string)\n",
    "* country: country of the projects creator \n",
    "* creator -> 'id': id of the creator -> to be used as categorical variable (part of json string)\n",
    "* goal: information on the amount of money needed to succeed in the local currency of the project\n",
    "* launched_at: start date? of the project ()\n",
    "* deadline: end date of the project ()\n",
    "* spotlight: project highlighted on the website\n",
    "* staff_pick: marked by a staff member of kickstarter (more attention drawn towards project)\n",
    "* state: (successful/failed/canceled/live/suspended) -> exclude 'live' and combine 'canceled', 'suspended' with 'failed'\n",
    "* static_usd_rate: exchange rate to transform goal in every column from current currency to USD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stakeholder: Project creator \n",
    "### Question: Is it useful to put much effort into launching a campaign on kickstarter? \n",
    "### Measure: Is the campaign likely to succeed or fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import os, json, re\n",
    "import pandas as pd \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### functions for pre-processing ####################################################################\n",
    "\n",
    "def extract_year_date_month(df, column):\n",
    "    '''Takes a column, converts it to datetime, and creates new columns with day, month and year\n",
    "    The new columns are named:\n",
    "        - column_weekday\n",
    "        - column_month\n",
    "        - column_year\n",
    "    '''\n",
    "    \n",
    "    # Convert column in df to datetime\n",
    "    df[column] = pd.to_datetime(df[column], unit='s')\n",
    "\n",
    "    # extract the day, month, and year components\n",
    "    df[column + '_' + 'weekday'] = df[column].dt.weekday\n",
    "    df[column + '_' + 'month'] = df[column].dt.month\n",
    "    #df[column + '_' + 'year'] = df[column].dt.year\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def duration(df, column1, column2):\n",
    "    '''Returns the duration in days between 2 columns with datetime and puts it into a new colum\n",
    "        - column1: start date\n",
    "        - column2: end date\n",
    "    '''\n",
    "    df['duration_days'] = (df[column2] - df[column1]).dt.days\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_to_usd(df):\n",
    "    return round(df['goal'] * df['static_usd_rate'],2)\n",
    "\n",
    "######### functions for analysing predictions ########################################################## \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Kickstarter_data/'\n",
    "data = pd.DataFrame()\n",
    "relevant_columns = ['category', 'country', 'creator', 'state', 'static_usd_rate', 'goal', 'launched_at', 'deadline']\n",
    "\n",
    "for file in sorted(os.listdir(directory)):\n",
    "    df_temp = pd.read_csv(directory+file)\n",
    "    data = pd.concat([data, df_temp[relevant_columns]], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on the json string columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the 'slug' parameter from the category column and drop the category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = data[\"category\"].apply(json.loads)\n",
    "cat_data = pd.DataFrame(cat_data.tolist())\n",
    "data['slug'] = cat_data['slug']\n",
    "data = data.drop(\"category\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the ID from the creator column and drop the creator column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"creator_id\"] = data[\"creator\"].apply(lambda x: re.findall(r'\\d+', x)[0])\n",
    "data = data.drop(\"creator\", axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude rows that have the state \"live\" \n",
    "#### we can't use them because we don't know wether the campaigns will succeed or fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['state'] != 'live'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign 1 to state == 'successful' and 0 to 'failed', 'canceled' or 'suspended'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['state'] = data['state'].apply(lambda x: 1 if x == 'successful' else 0)\n",
    "\n",
    "data['state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on the datetime columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date-data to type date.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['launched_at'] = pd.to_datetime(data['launched_at'], unit='s')\n",
    "data['deadline'] = pd.to_datetime(data['deadline'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on creator_id column \n",
    "### Create a new array, indicating wether a creator had a successful campaign before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creators = data.creator_id.value_counts().to_frame().reset_index()\n",
    "# multi_creators = creators[creators['count'] > 1]\n",
    "# multi_creators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For now: Drop the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('creator_id', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract weekday and month of kickstarter project launch, as well as the duration of the kickstarter project and drop the \"launched_at\" and \"deadline\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extract_year_date_month(data, 'launched_at')\n",
    "data = duration(data, 'launched_at', 'deadline')\n",
    "\n",
    "data = data.drop(['launched_at', 'deadline'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert unit of \"goal\" to USD and drop \"static_usd_rate\" and \"goal\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['goal_in_usd'] = data.apply(convert_to_usd, axis=1)\n",
    "data = data.drop(['static_usd_rate', 'goal'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['goal_in_usd'] < 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.state.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes:  % succeeded,  % failed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country to north america True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"north_america\"] = data[\"country\"].apply(lambda x: 1 if x in ['US', 'CA'] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.north_america.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('country', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.slug.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"slug\"] = data[\"slug\"].apply(lambda x: re.split(r'/', x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.slug.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "data['slug'] = le.fit_transform(data['slug'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_data = pd.get_dummies(data, columns=['slug', 'launched_at_weekday', 'launched_at_month'], drop_first=True)\n",
    "oh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.goal_in_usd.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.backers_count.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['spotlight', 'state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['spotlight'] != data['state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['staff_pick'] != data['state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('spotlight', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('staff_pick', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['goal_in_usd'] < 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data,hue='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTICS REGRESSION\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "#X = data.drop('state',axis=1)\n",
    "X = data.drop(\"state\", axis =1)\n",
    "y = data[\"state\"]\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# Train-test-split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Modelling\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train_scaled, y_train)\n",
    "y_pred = logistic_regression.predict(X_test_scaled)\n",
    "\n",
    "# Confusion matrix using pandas crosstab\n",
    "conf_matrix= confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True);\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "#X = data.drop('state',axis=1)\n",
    "X = oh_data.drop(\"state\", axis =1)\n",
    "y = oh_data[\"state\"]\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# Train-test-split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Modelling\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train_scaled, y_train)\n",
    "y_pred = logistic_regression.predict(X_test_scaled)\n",
    "\n",
    "# Confusion matrix using pandas crosstab\n",
    "conf_matrix= confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True);\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
