{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this Notebook, the gridsearches for the different types of models are shown.\n",
    "\n",
    "For this specific Project it was chosen to optimize the models with respect to Precision, as it is important to not say a company they will most likely succeed with their Campaign and then won't. Therefore we aim at reducing the false positives while still having a sufficent amount of campaigns classified as 'most_likely' successfull. Nevertheless, assuming the accuracy is easier interpretable by a potential stakeholder, the models accuracies and accuracy scores are saved for comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all cells in this notebook need to be executed, as the best models resulting from the grid searches are saved in the models folder. Executing the grid searcher, especially the grid search for the KNN algorithm takes many hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from utils.evaluation import *                  #contains functions used for model evaluation\n",
    "from utils.Preprocessing_funct import *         #contains functions used for pre-processing\n",
    "RSEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the differently scaled train- and test-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load X_train, X_test, y_train, y_test \n",
    "\n",
    "y_train = pd.read_csv('data/ytrain.csv')\n",
    "y_test = pd.read_csv('data/y_test.csv')\n",
    "\n",
    "X_train = pd.read_csv('data/unscaled_Xtrain.csv')\n",
    "X_test = pd.read_csv('data/unscaled_Xtest.csv')\n",
    "\n",
    "X_train_stdscaled = pd.read_csv('data/stdscaled_Xtrain.csv')\n",
    "X_test_stdscaled = pd.read_csv('data/stdscaled_Xtest.csv')\n",
    "\n",
    "X_train_mmscaled = pd.read_csv('data/mmscaled_Xtrain.csv')\n",
    "X_test_mmscaled = pd.read_csv('data/mmscaled_Xtest.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "Various models, including Logistic Regression, k-nearest neighbours, random forest and xgboost were optimized by performing a grid search. The accuracy scores of the respective best models were saved in the 'accuracies.txt' file and the confusion matrices in the images folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - Gridsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################################\n",
    "# ###### Don't execute this cell if not intending to repeat grid search #########################\n",
    "# ###############################################################################################\n",
    "\n",
    "# # Logistic Regression\n",
    "# logreg_clf = LogisticRegression(max_iter=100000)\n",
    "\n",
    "# # define parameter grid for grid search\n",
    "# # params_log_reg_1st_try = {\"penalty\": [\"l1\",\"l2\"],\n",
    "# #                \"solver\": [\"saga\", \"liblinear\"],\n",
    "# #                \"C\": [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]           \n",
    "# # }\n",
    "\n",
    "# # as params maxed out C, try larger Cs\n",
    "\n",
    "# params_log_reg = {\"penalty\": [\"l1\",\"l2\"],\n",
    "#                \"solver\": [\"saga\", \"liblinear\"],\n",
    "#                \"C\": [100.0, 1000.0, 10000.0]           \n",
    "# }\n",
    "\n",
    "# # Instantiate gridsearch\n",
    "# gs_log_reg = GridSearchCV(logreg_clf, param_grid=params_log_reg, cv = 5,n_jobs = -1, scoring='precision')\n",
    "\n",
    "# # fit gridsearch object to data\n",
    "# gs_log_reg.fit(X_train_stdscaled, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best score\n",
    "# print('Best score:', round(gs_log_reg.best_score_, 3))\n",
    "# # Best parameters\n",
    "# print('Best parameters:', gs_log_reg.best_params_)\n",
    "# print('----------'*8)\n",
    "\n",
    "# #save best model\n",
    "\n",
    "# # best_lr = gs_log_reg.best_estimator_\n",
    "# # pickle.dump(best_lr, open('./models/best_lr_model', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Logistic Regression Gridsearch\n",
    "**Best score:** 0.672 \\\n",
    "**Best parameters:** {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the best Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = pickle.load(open('./models/best_lr_model', 'rb'))     # load best model from the model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on best model\n",
    "y_pred_best_lr = best_lr.predict(X_test_stdscaled)\n",
    "\n",
    "# Plot classification report and confusion matrix\n",
    "vis_results(y_test, y_pred_best_lr, 'LogReg', savefig=True)\n",
    "\n",
    "# Accuracy score\n",
    "accuracies['LogReg'] = accuracy_score(y_test, y_pred_best_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN - Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################################\n",
    "# ###### Don't execute this cell if not intending to repeat grid search #########################\n",
    "# ###############################################################################################\n",
    "\n",
    "# # Train model\n",
    "# knn_clf = KNeighborsClassifier()\n",
    "\n",
    "# params_KNN = {\"n_neighbors\" : [3,5,7], #this actually defines the model you use\n",
    "#               \"weights\" : [\"uniform\", \"distance\"],\n",
    "#               \"p\" : [1, 2, 3],\n",
    "#               \"algorithm\": [\"ball_tree\", \"brute\"]\n",
    "#              }\n",
    "\n",
    "# # Instantiate gridsearch and define the metric to optimize \n",
    "# gs_KNN = GridSearchCV(knn_clf, param_grid=params_KNN, cv = 5, n_jobs = -1, scoring='precision', verbose=5) \n",
    "\n",
    "\n",
    "# # fit gridsearch object to data\n",
    "# gs_KNN.fit(X_train_mmscaled, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best score\n",
    "# print('Best score:', round(gs_KNN.best_score_, 3))\n",
    "# # Best parameters\n",
    "# print('Best parameters:', gs_KNN.best_params_)\n",
    "# print('----------'*8)\n",
    "\n",
    "# # save best model\n",
    "\n",
    "# #best_knn = gs_KNN.best_estimator_\n",
    "# #pickle.dump(best_knn, open('./models/best_knn_model', 'wb'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results KNN Gridsearch \n",
    "\n",
    "**Best score:** 0.678 \\\n",
    "**Best parameters:** {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the best KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = pickle.load(open('./models/best_knn_model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on best model\n",
    "y_pred_best_knn = best_knn.predict(X_test_mmscaled)\n",
    "\n",
    "# Plot classification report and confusion matrix\n",
    "vis_results(y_test, y_pred_best_knn, 'KNN', savefig=True)\n",
    "\n",
    "# Accuracy score\n",
    "accuracies['KNN'] = accuracy_score(y_test, y_pred_best_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Gridsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################################\n",
    "# ###### Don't execute this cell if not intending to repeat grid search #########################\n",
    "# ###############################################################################################\n",
    "\n",
    "\n",
    "# # Train model\n",
    "# rf_clf = RandomForestClassifier()\n",
    "\n",
    "# params_rf = {\"n_estimators\": range(70,110,10),\n",
    "#              \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "#              \"min_samples_leaf\": range(7,15,2),\n",
    "#              \"max_features\": ['sqrt', 'log2'],\n",
    "#              \"class_weight\": ['balanced','balanced_subsample'],\n",
    "#              \"max_samples\": [0.6, 0.7, 0.8]\n",
    "#              }\n",
    "\n",
    "# # Instantiate gridsearch and define the metric to optimize \n",
    "# gs_rf = GridSearchCV(rf_clf, param_grid=params_rf, cv = 5, n_jobs = -1, scoring='precision')\n",
    "\n",
    "\n",
    "# # fit gridsearch object to data\n",
    "# gs_rf.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best score\n",
    "# print('Best score:', round(gs_rf.best_score_, 3))\n",
    "# # Best parameters\n",
    "# print('Best parameters:', gs_rf.best_params_)\n",
    "# print('----------'*8)\n",
    "\n",
    "# #save best model\n",
    "\n",
    "# # best_rf = gs_rf.best_estimator_\n",
    "# # pickle.dump(best_rf, open('./models/best_rf_model', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Random Forest Gridsearch\n",
    "\n",
    "**Best score:** 0.722 \\\n",
    "**Best parameters:** {'class_weight': 'balanced', 'criterion': 'log_loss', 'max_features': 'sqrt', 'max_samples': 0.8, 'min_samples_leaf': 11, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the best Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = pickle.load(open('./models/best_rf_model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on best model\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Plot classification report and confusion matrix\n",
    "vis_results(y_test, y_pred_best_rf, 'RandomForest', savefig=True)\n",
    "\n",
    "# Accuracy score\n",
    "accuracies['RandomForest'] = accuracy_score(y_test, y_pred_best_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################################\n",
    "# ###### Don't execute this cell if not intending to repeat grid search #########################\n",
    "# ###############################################################################################\n",
    "\n",
    "# # Train model\n",
    "# xgb_clf = XGBClassifier()\n",
    "\n",
    "# params_xgb = {\"n_estimators\": [100, 200, 300, 400, 500],\n",
    "#              \"learning_rate\": [0.01, 0.1, 1],\n",
    "#              \"subsample\": [0.25, 0.5, 0.75],\n",
    "#              \"max_depth\": [7, 13, 23],\n",
    "#              \"colsample_bytree\": [0.3, 0.5, 0.85, 1]\n",
    "#              }\n",
    "\n",
    "# # Tested second set of params because maximum of max_depth and subsamples and minimum of n_estimators was found as best parameters,\n",
    "# # however no improvement was seen.\n",
    "# # params_xgb2 = {\"n_estimators\": [50, 100, 200],\n",
    "#             #  \"learning_rate\": [0.01, 0.1],\n",
    "#             #  \"subsample\": [0.5, 0.75, 1],\n",
    "#             #  \"max_depth\": [25, 30, 50],\n",
    "#             #  \"colsample_bytree\": [0.85]\n",
    "#             #  }\n",
    "\n",
    "\n",
    "# # Instantiate gridsearch and define the metric to optimize \n",
    "# gs_xgb = GridSearchCV(xgb_clf, param_grid=params_xgb, cv = 5, n_jobs = -1, scoring='precision', verbose=5)\n",
    "\n",
    "\n",
    "# # fit gridsearch object to data\n",
    "# gs_xgb.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best score\n",
    "# print('Best score:', round(gs_xgb.best_score_, 3))\n",
    "# # Best parameters\n",
    "# print('Best parameters:', gs_xgb.best_params_)\n",
    "# print('----------'*8)\n",
    "\n",
    "# # save best model\n",
    "\n",
    "# # best_xgb = gs_xgb.best_estimator_\n",
    "# # pickle.dump(best_xgb, open('./models/best_xgb_model', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results XGBoost Gridsearch \n",
    "\n",
    "**Best score:** 0.705 \\\n",
    "**Best parameters:** {'colsample_bytree': 0.85, 'learning_rate': 0.1, 'max_depth': 23, 'n_estimators': 100, 'subsample': 0.75}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the best XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = pickle.load(open('./models/best_xgb_model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on best model\n",
    "y_pred_best_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Plot classification report and confusion matrix\n",
    "vis_results(y_test, y_pred_best_xgb, 'XGBoost', savefig=True)\n",
    "\n",
    "# Accuracy score\n",
    "accuracies['XGBoost'] = accuracy_score(y_test, y_pred_best_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the accuracies of the different models\n",
    "\n",
    "sorted_accuracies = dict(sorted(accuracies.items(), key=lambda x:x[1]))\n",
    "# pickle.dump(sorted_accuracies, open('accuracies.txt', 'wb')) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
